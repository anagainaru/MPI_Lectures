{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MPI \n",
    "**Message Passing Interface**\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<div>\n",
    "Lectures by: Ana Gainaru <br/>\n",
    "    <small>CS6320 Algorithms for parallel computing</small>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Slides\n",
    "\n",
    "- Online at: https://anagainaru.github.io/ArborX/#/\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "### Code from slide available to download\n",
    "- https://github.com/anagainaru/MPI_Lectures\n",
    "    - Python code\n",
    "    \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<div class=\"box\"> For future questions: ana.gainaru@vanderbilt.edu </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parallel Programming\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<img src=\"./figures/parallel_arch.png\" alt=\"Architecture\" align=\"center\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Types of Parallel Computing Models\n",
    "\n",
    "**Implicit Parallelism**: Parallelizing Compilers\n",
    "\n",
    "**Explicit Parallelism**:  Data Parallel | Task parallel | Message Passing (**MPI**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Data Parallel - the same instructions are carried out simultaneously on multiple data items `SIMD`\n",
    "* Task Parallel - different instructions on different data `MIMD`\n",
    "\n",
    "* `SPMD` (single program, multiple data) not synchronized at individual operation level\n",
    "     - SPMD is equivalent to MIMD since each MIMD program can be made od SPMD "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Message passing (MPI) is for MIMD/SPMD parallelism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The Message Passing Model\n",
    "\n",
    "- Consist of separate processes, each with its own address space\n",
    "    - Programmer manages memory by placing data in a particular process\n",
    "\n",
    "- Data is sent explicitly between processes \n",
    "    - Programmer manages memory motion\n",
    "\n",
    "- Multi-process communication (Collective operations)\n",
    "    - *Algorithm (performance) defined by the programming language*\n",
    "    - Programmer selects subset of processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The Message Passing Model\n",
    "\n",
    "- A process is\n",
    "    - a program counter \n",
    "    - address space\n",
    "\n",
    "- Processes may have multiple threads (program counters and associated stacks) sharing a single address space.\n",
    "\n",
    "<cite> MPI is for communication among processes, with separate address spaces </cite>\n",
    "\n",
    "- Interprocess communication consists of\n",
    "     - Moving data from one process’s address space to another’s\n",
    "     - Synchronization\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# In These Lectures\n",
    "\n",
    "<pre>\n",
    "<small>\n",
    "\n",
    "<strong>1. Introduction to MPI </strong>\n",
    "    - Library and implementation characteristics\n",
    "    - MPI for python\n",
    "    - Error handling\n",
    "\n",
    "<strong>2. Blocking point-to-point communication</strong>\n",
    "    - Sending and receiving with <em>MPI_Send</em> and <em>MPI_Recv</em>\n",
    "    - Dynamic receiving with <em>MPI_Probe</em> and <em>MPI_Status</em>\n",
    "    - Groups and communicators\n",
    "    \n",
    "<strong>3. Non-blocking communication</strong>\n",
    "\n",
    "<strong>4. Collective communication</strong>\n",
    "    - Synchronization (<em>Barrier</em>)\n",
    "    - Data movement (<em>Broadcast, Gather, Scatter, Allgather, Alltoall</em>)\n",
    "    - Collective computation (<em>Reduce, AllReduce, Scan, Exscan, Reduce_scatter</em>)\n",
    "    - Define your own collective routine\n",
    "    - Non-Blocking Collective Operations\n",
    "    \n",
    "<strong>5. Topology mapping and neighborhood collectives</strong>\n",
    "\n",
    "<strong>6. Profiling MPI applications</strong>\n",
    "\n",
    "\n",
    "</small>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Programming With MPI \n",
    "\n",
    "MPICH / OpenMPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Programming With MPI \n",
    "\n",
    "- MPI is a library\n",
    "    - All operations are performed with routine calls\n",
    "    - Basic definitions in\n",
    "        - mpi.h for C\n",
    "        - MPI or MPI_F08 module for Fortran\n",
    "    - Implementation\n",
    "        - MPICH: high-quality reference implementation of the latest MPI standard\n",
    "        - OpenMPI: common case, both in terms of usage and network conduits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- MPI for Python\n",
    "    - mpi4py module using `pickle` under the hood\n",
    "        - implements binary protocols for serializing and de-serializing a Python object structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Launching MPI jobs\n",
    "\n",
    "```bash\n",
    "mpiexec –np ${RANKS} python ${PATH_TO_SCRIPT}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "print(\"Hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mpiexec -n 4 python script.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Hello world<br/>\n",
    "Hello world<br/>\n",
    "Hello world<br/>\n",
    "Hello world<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# MPI Environment\n",
    "\n",
    "- Two important issues\n",
    "    - Initializing all MPI’s global and internal variables\n",
    "        - e.g. Global communicator that allows all processors to communicate\n",
    "    - Giving processes enough information to communicate with each other\n",
    "        - Number of total processes participating in this computation\n",
    "        - Which process am I from all processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- MPI provides functions for all issues:\n",
    "    - `MPI_Initialize`/`MPI_Finalize`\n",
    "    - `MPI_Comm_size` reports the number of processes\n",
    "    - `MPI_Comm_rank` reports the rank, a number between 0 and size-1, identifying the calling process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```C++\n",
    "#include “mpi.h”\n",
    "\n",
    "int main(int argc, char *argv[])\n",
    "{\n",
    " int rank, size, i, provided;\n",
    " float A(10);\n",
    "\n",
    " MPI_Init_thread(&argc, &argv, MPI_THREAD_SINGLE, &provided);\n",
    "    \n",
    " MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    " MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    " \n",
    " for (i=0; i<10; i++)\n",
    "     A[i] = i * rank;\n",
    " \n",
    " printf(\"My rank %d of %d\\n\", rank, size );\n",
    "    \n",
    " printf(\"Here are my values for A\\n\");\n",
    " for (i=0; i<10; i++) printf(\"%f \", A[i]);\n",
    " printf(\"\\n\");\n",
    " \n",
    " MPI_Finalize();\n",
    "} \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size() \n",
    "\n",
    "A = [i * rank for i in range(5)]\n",
    "\n",
    "print(\"My rank %d of %d\" %(rank, size));\n",
    "print(\"My values for A: %s\" %(A));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```\n",
    "My rank 0 of 4\n",
    "My rank 1 of 4\n",
    "My rank 2 of 4\n",
    "My values for A: [0, 0, 0, 0, 0]\n",
    "My values for A: [0, 2, 4, 6, 8]\n",
    "My values for A: [0, 1, 2, 3, 4]\n",
    "My rank 3 of 4\n",
    "My values for A: [0, 3, 6, 9, 12]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Main MPI characteristics\n",
    "\n",
    "All MPI programs begin with MPI_Init_thread and end with MPI_Finalize\n",
    "- `MPI_COMM_WORLD` is defined by mpi.h (in C) or the MPI module\n",
    "    - includes all processes in the MPI “job”\n",
    "-  Each statement executes independently in each process\n",
    "     - including the print/printf statements\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- I/O to standard output __is not__ part of MPI\n",
    "     - output order undefined (may be interleaved by character, line, or blocks of characters) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# MPI Initialization\n",
    "\n",
    "- Programmer can request the level of thread safety required for the program\n",
    "    - E.g. Needed to use OpenMP with MPI \n",
    "&nbsp;\n",
    "\n",
    "- `MPI_THREAD_SINGLE` gives the same behavior as MPI_Init \n",
    "    - one thread will execute\n",
    "- `MPI_THREAD_FUNNELED` The process may be multi-threaded\n",
    "    - only the main thread will make MPI calls \n",
    "    - all MPI calls are funneled to the main thread\n",
    "- `MPI_THREAD_SERIALIZED` The process may be multi-threaded, and multiple threads may make MPI calls, but only one at a time\n",
    "    - MPI calls are not made concurrently from two distinct threads \n",
    "    - all MPI calls are serialized\n",
    "- `MPI_THREAD_MULTIPLE` Multiple threads may call MPI, with no restrictions.\n",
    "\n",
    "<cite> MPI_Init_thread is used since MPI-2 </cite>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# MPI for Python\n",
    "\n",
    "- At import time (`import mpi4py`)\n",
    "    - the module initializes the MPI execution environment calling `MPI_Init_thread()`\n",
    "    - installs an exit hook to automatically call `MPI_Finalize()` just before the Python process terminates\n",
    "\n",
    "- You can set runtime configuration options (e.g. automatic initialization, thread_level) via `mpi4py.rc()`\n",
    "- By default importing the MPI submodule calls `MPI_Init()`\n",
    "     - calling Init() or Init_thread()more than once violates the MPI standard\n",
    "     - This will lead to a Python exception or an abort in C/C++\n",
    "     - use `Is_initialized()` to test for initialization \n",
    "         - similarly for Finilize: `Is_finalized()`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Error handling\n",
    "\n",
    "By default, an error causes all processes to abort.\n",
    "\n",
    "- The user can cause routines to return (with an error code) instead.\n",
    "- A user can also write and install custom error handlers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Error handling\n",
    "\n",
    "- MPI has error codes and classes\n",
    "    - MPI routines return error codes\n",
    "    - Each code belongs to an error class\n",
    "    - The returned error code is implementation specific\n",
    "    - The only error code that MPI standard itself defines is `MPI_SUCCESS`, i.e., no error\n",
    "    - The meaning of an error code can be extracted by calling function `MPI_Error_string`. \n",
    "\n",
    "- An MPI implementation can use error codes to return instance-specific information on the error\n",
    "    - MPICH does this, providing more detailed and specific messages\n",
    "    - There are routines to convert an error code to text and to find the class for a code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Error handling\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "```C++\n",
    "MPI_Errhandler_set(MPI_COMM_WORLD, MPI_ERRORS_RETURN);\n",
    "\n",
    "error_code = MPI_Send(send_buffer, strlen(send_buffer) + 1,\n",
    "                      MPI_CHAR, addressee, tag, MPI_COMM_WORLD);\n",
    "\n",
    "if (error_code != MPI_SUCCESS){\n",
    "    char error_string[BUFSIZ];\n",
    "    int length_of_error_string;\n",
    "\n",
    "    MPI_Error_string(error_code, error_string, &length_of_error_string);\n",
    "    \n",
    "    fprintf(stderr, \"%3d: %s\\n\", my_rank, error_string);\n",
    "    send_error = TRUE;\n",
    "} \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# MPI for python\n",
    "\n",
    "- mpi4py overrides the default `MPI.ERRORS_ARE_FATAL` error handler in favor of `MPI.ERRORS_RETURN`\n",
    "    - which allows translating MPI errors in Python exceptions.\n",
    " \n",
    "- MPI errors as Python exceptions, can be dealt with the common `try…except…finally` clauses\n",
    "    - Unhandled MPI exceptions will print a traceback which helps in locating problems in source code.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<div class=\"box\"> Automatic MPI finalization combined with unhandled exceptions can lead to deadlocks. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# MPI for python\n",
    "\n",
    "### Automatic MPI finalization + unhandled exceptions can lead to deadlocks.\n",
    "\n",
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "assert MPI.COMM_WORLD.Get_size() > 1\n",
    "rank = MPI.COMM_WORLD.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    1/0\n",
    "    MPI.COMM_WORLD.send(None, dest=1, tag=42)\n",
    "elif rank == 1:\n",
    "    MPI.COMM_WORLD.recv(source=0, tag=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# MPI for python error handling\n",
    "\n",
    "- Handle exceptions in your code manually\n",
    "\n",
    "OR\n",
    "\n",
    "- Run Python code passing -m mpi4py in the command line\n",
    "    - In case of unhandled exceptions, the finalizer hook will call `MPI_Abort()` on the `MPI_COMM_WORLD` communicator\n",
    "        - This will abort the MPI execution environment.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "```bash\n",
    "mpiexec -n ${NUM_PROCS} python -m mpi4py ${PYTHON_FILE} [${ARG}]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MPI Basic Send/Receive\n",
    "\n",
    "![Send Receive](figures/send_recv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Identify the process you want to communicate with \n",
    "2. Describe the data\n",
    "3. Know when the send/receive operations are complete \n",
    "4. Recognize messages sent to you by other processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# 1. Identify the process to communicate with \n",
    "\n",
    "- Processes can be collected into groups.\n",
    "- Each message is sent in a context, and must be received in the same context.\n",
    "\n",
    "<cite>A group and context together form a communicator (*) </cite>\n",
    "\n",
    "<small>(*) the context (or ID) that differentiates one communicator from another and the group of processes contained by the communicator</small>\n",
    "\n",
    "- A process is identified by its rank in the group associated with a communicator.\n",
    "    - `MPI_COMM_WORLD` is enough for most applications\n",
    "\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "```C++\n",
    "MPI_Comm_split(\n",
    "\tMPI_Comm comm,\n",
    "\tint color,             // for split\n",
    "\tint key,               // for ordering\n",
    "\tMPI_Comm* newcomm)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Get the rank and size in the original communicator\n",
    "from mpi4py import MPI\n",
    "\n",
    "world_rank = MPI.COMM_WORLD.Get_rank()\n",
    "world_size = MPI.COMM_WORLD.Get_size()\n",
    "\n",
    "# Determine color based on even/odd ranks\n",
    "color = world_rank / 2; \n",
    "\n",
    "# Split the communicator based on the color and use the\n",
    "# original rank for ordering\n",
    "new_comm = MPI.COMM_WORLD.Split(color, world_rank)\n",
    "\n",
    "new_rank = new_comm.Get_rank()\n",
    "new_size = new_comm.Get_size()\n",
    "\n",
    "print(\"World rank/size: %d/%d -- New rank/size: %d/%d\" %(\n",
    "            world_rank, world_size, new_rank, new_size));\n",
    "\n",
    "new_comm.Free()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```\n",
    "World rank/size: 0/4 -- New rank/size: 0/2\n",
    "World rank/size: 1/4 -- New rank/size: 1/2\n",
    "World rank/size: 2/4 -- New rank/size: 0/2\n",
    "World rank/size: 3/4 -- New rank/size: 1/2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# 2. Describe the data\n",
    "\n",
    "### The message buffer is described by `(start, count, datatype)`\n",
    "\n",
    "- Datatype can be:\n",
    "    - Predefined corresponding to a data type from the language (MPI_CHAR, MPI_INT, MPI_DOUBLE, etc)\n",
    "    - a contiguous array of MPI datatypes\n",
    "    - a strided block of datatypes\n",
    "    - an indexed array of blocks of datatypes\n",
    "    - an arbitrary structure of datatypes \n",
    "\n",
    "- There are MPI functions to construct custom datatypes\n",
    "    - e.g. an array of (int, float) pairs, or a row of a matrix stored columnwise\n",
    "\n",
    "<cite> mpi4py uses protocols for packing and unpacking a Python object structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# 2. Describe the data\n",
    "\n",
    "- Create an MPI datatype from a general set of datatypes, displacements, and block sizes\n",
    "\n",
    "```C++\n",
    "int MPI_Type_create_struct(\n",
    "  int count,\n",
    "  int array_of_blocklengths[],\n",
    "  MPI_Aint array_of_displacements[],\n",
    "  MPI_Datatype array_of_types[],\n",
    "  MPI_Datatype *newtype\n",
    ");\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def definetype():\n",
    "    dtypes = [MPI.INT, MPI.DOUBLE]\n",
    "    dt_size = MPI.INT.size + MPI.DOUBLE.size\n",
    "    displ = [0, MPI.INT.size]\n",
    "\n",
    "    new_dtype = MPI.Datatype.Create_struct([1, 1], displ, dtypes)\n",
    "    new_dtype = new_dtype.Create_resized(0, dt_size)\n",
    "    new_dtype.Commit()\n",
    "    return new_dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# 3. Recognize messages sent to you by other processes\n",
    "\n",
    "- Messages are sent with an accompanying user-defined integer tag\n",
    "    - Used to assist the receiving process in identifying the message.\n",
    "    - Messages can be screened at the receiving end by specifying a specific tag, or\n",
    "    - not screened by specifying `MPI_ANY_TAG` as the tag in a receive.\n",
    "\n",
    "- Some non-MPI message-passing systems have called tags “message types”.\n",
    "    - MPI calls them tags to avoid confusion with datatypes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    sdata = {'a': 7, 'b': 3.14}\n",
    "    comm.send(sdata, dest=1, tag=11)\n",
    "elif rank == 1:\n",
    "    rdata = comm.recv(source=0, tag=11)\n",
    "    print(rdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "{'a': 7, 'b': 3.14}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# 4. Know when the send/receive operations are complete \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "**Blocking / Non-blocking**\n",
    "\n",
    "- The message-passing approach makes the exchange of data cooperative.\n",
    "- Data is explicitly sent by one process and received by another.\n",
    "- An advantage is that any change in the receiving process’s memory is made with the receiver’s explicit participation.\n",
    "- Communication and synchronization are combined.\n",
    "\n",
    "**One sided communication**\n",
    "\n",
    "- One-sided operations between processes include remote memory reads and writes\n",
    "- Only one process needs to explicitly participate.\n",
    "- An advantage is that communication and synchronization are decoupled "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# MPI Basic (Blocking) Send \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "`MPI_SEND (start, count, datatype, dest, tag, comm)`\n",
    "\n",
    "- The message buffer is described by (start, count, datatype).\n",
    "- The target process is specified by dest, which is the rank of the target process in the communicator specified by comm.\n",
    "- When this function returns, the data has been delivered to the system and the buffer can be reused\n",
    "    - The message may not have been received by the target process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# MPI Basic (Blocking) Receive\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "`MPI_RECV(start, count, datatype, source, tag, comm, status)`\n",
    "\n",
    "- Waits until a matching (on source and tag) message is received from the system, and the buffer can be used.\n",
    "- source is rank in communicator specified by comm, or MPI_ANY_SOURCE.\n",
    "- status contains further information\n",
    "- Receiving fewer than count occurrences of datatype is OK, but receiving more is an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Blocking Send/Receive Summary\n",
    "\n",
    "![Send Receive](figures/send_recv_proc.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Blocking Send/Receive Summary\n",
    "\n",
    "<img src=\"./figures/send_recv_proc.png\" alt=\"Send Receive\" align=\"left\" width=\"400\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```C++\n",
    "...\n",
    "\n",
    "if(rank == 0){\n",
    "    // generate data\n",
    "    MPI_Send(&sdata, 1, MPI_INT, 1, 100,\n",
    "             MPI_COMM_WORLD);\n",
    "} \n",
    "if(rank == 1){\n",
    "    MPI_Recv(&rdata, 1, MPI_INT, MPI_ANY_SOURCE, MPI_ANY_TAG, \n",
    "             MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
    "    //do somthing with data\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Send array of (int32, float64) tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def definetype():\n",
    "    dtypes = [MPI.INT, MPI.DOUBLE]\n",
    "    dt_size = MPI.INT.size + MPI.DOUBLE.size\n",
    "    displ = [0, MPI.INT.size]\n",
    "\n",
    "    new_dtype = MPI.Datatype.Create_struct([1, 1], displ, dtypes)\n",
    "    new_dtype = new_dtype.Create_resized(0, dt_size)\n",
    "    new_dtype.Commit()\n",
    "    return new_dtype\n",
    "\n",
    "def fill_data(data, num):\n",
    "    for i in range(num):\n",
    "        data[i][0] = i + 1\n",
    "        data[i][1] = 3.14 * (i + 1)\n",
    "\n",
    "mytype = definetype()\n",
    "data = np.zeros(2, dtype=\"int32, double\")\n",
    "if rank == 0:\n",
    "    comm.Recv([data, mytype], source=1, tag=0)\n",
    "    print(data)\n",
    "elif rank == 1:\n",
    "    fill_data(data, 2)\n",
    "    comm.Send([data, mytype], dest=0, tag=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[(1, 3.14) (2, 6.28)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Non-blocking communication\n",
    "\n",
    "![Blocking vs nonblocking](./figures/non_blocking.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Why Non-blocking?\n",
    "\n",
    "1. Overlapping communication and computation\n",
    "    - It can increase performance of some applications (not always)\n",
    "    \n",
    "2. Avoiding deadlocks\n",
    "    - Related to message ordering\n",
    "    - Due to completion depending on size of message and amount of system buffering\n",
    "\n",
    "<img src=\"./figures/send_recv_proc.png\" alt=\"Send Receive\" width=\"400\"/>\n",
    "\n",
    "- Non blocking communication\n",
    "    - Send/Recv routines return before transfer is complete\n",
    "    - and we wait later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Deadlock example\n",
    "\n",
    "- Send a large message from process 0 to process 1\n",
    "     - If there is insufficient storage at the destination, the send must wait for the user to provide the memory space (through a receive)\n",
    "\n",
    "- What happens with this code?\n",
    "\n",
    "<img src=\"./figures/blocking_deadlock.png\" alt=\"Deadlock\" width=\"500\"/>\n",
    "\n",
    "- This is called **unsafe** because it depends on the availability of system buffers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Deadlock solution\n",
    "\n",
    "- Order the operations more carefully\n",
    "\n",
    "\n",
    "- Supply receive buffer at same time as send (`MPI_Sendrecv`)\n",
    "- Supply own buffer space (`MPI_Bsend`)\n",
    "\n",
    "\n",
    "- Use non-blocking operations\n",
    "     - **Safe**, but\n",
    "     - does not guarantee to be asynchronous or concurrent\n",
    "     - not always faster "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# MPI Non-blocking operations \n",
    "\n",
    "- Return immediately \n",
    "    - give **request handles** that can be tested and waited on for completion.\n",
    "\n",
    "\n",
    "<div class=\"highlight\">\n",
    "<pre>\n",
    "\n",
    "\n",
    "MPI_Request <strong>request</strong>;\n",
    "\n",
    "MPI_Isend(start, count, datatype, dest, tag, comm, &<strong>request</strong>);\n",
    " \n",
    "MPI_Irecv(start, count, datatype, dest, tag, comm, &<strong>request</strong>);\n",
    "\n",
    "MPI_Wait(&<strong>request</strong>, &status);\n",
    "</pre>\n",
    "</div>\n",
    "\n",
    "- One can also test without waiting:\n",
    "\n",
    "<pre>\n",
    "\n",
    "MPI_Test(&<strong>request</strong>, &flag, &status); \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# MPI for python ping pong example\n",
    "\n",
    "- Using numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "import numpy\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "assert comm.size == 2\n",
    "\n",
    "sdata = numpy.array([(rank+1) * i for i in range(10)])\n",
    "rdata = numpy.array([0] * 10)\n",
    "\n",
    "if comm.rank == 0:\n",
    "    target = 1\n",
    "else:\n",
    "    target = 0\n",
    "\n",
    "request = comm.Isend([sdata, MPI.INT], dest=target, tag=10)\n",
    "comm.Recv([rdata, MPI.INT], source=target, tag=MPI.ANY_TAG)\n",
    "request.Wait()\n",
    "\n",
    "print(\"rank: %d received data %s\" %(rank, rdata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```\n",
    "rank 1: received data [0 1 2 3 4 5 6 7 8 9]\n",
    "rank 0: received data [0 2 4 6 8 10 12 14 16 18]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Multiple Completions\n",
    "\n",
    "- Waiting on multiple requests:\n",
    "\n",
    "<pre>\n",
    "\n",
    "MPI_Waitall(count, <strong>array_of_requests</strong>, array_of_statuses);\n",
    "\n",
    "MPI_Waitany(count, <strong>array_of_requests</strong>, &index, &status);\n",
    "\n",
    "MPI_Waitsome(incount, <strong>array_of_requests</strong>,  &outcount, array_of_indices,\n",
    "             array_of_statuses);\n",
    "</pre>\n",
    "\n",
    "- There are corresponding versions of test for each of these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Modes for sending messages:\n",
    "\n",
    "-  Synchronous mode (`MPI_Ssend`)\n",
    "    - The send does not complete until a matching receive has begun. \n",
    "    - Unsafe programs deadlock.\n",
    "\n",
    "-  Buffered mode (`MPI_Bsend`)\n",
    "    - The user supplies a buffer to the system for its use. \n",
    "    - User can allocate enough memory to make an unsafe program safe.\n",
    "\n",
    "-  Ready mode (`MPI_Rsend`)\n",
    "    - User guarantees that a matching receive has been posted.\n",
    "    - Allows access to fast protocols\n",
    "    - *Undefined behavior if matching receive not posted*\n",
    "\n",
    "-  Non-blocking versions for all operations (MPI_Issend, etc.)\n",
    "\n",
    "<cite> MPI_Recv receives messages sent in any mode. </cite>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# MPI_Sendrecv\n",
    "\n",
    "- Simultaneous send and receive\n",
    "    - Send and receive datatypes (even type signatures) may be different.\n",
    "    - Can use Sendrecv with plain Send or Recv (or Irecv or Ssend_init, ...)\n",
    "\n",
    "- Intended for sending data in a \"chain\"\n",
    "    - For instance, 0 sends to 1 while 1 sends to 2 while 2 sends to 0. \n",
    "  \n",
    "```C++\n",
    "int MPI_Sendrecv(\n",
    "  void *sendbuf,\n",
    "  int sendcount,\n",
    "  MPI_Datatype sendtype,\n",
    "  int dest,\n",
    "  int sendtag,\n",
    "  void *recvbuf,\n",
    "  int recvcount,\n",
    "  MPI_Datatype recvtype,\n",
    "  int source,\n",
    "  int recvtag,\n",
    "  MPI_Comm comm,\n",
    "  MPI_Status *status\n",
    ");\n",
    "```\n",
    "\n",
    "### Both send and receive must be successful for the operation to succeed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# MPI_sendrecv example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "to = (rank + 1) % size\n",
    "fr = (rank - 1) % size\n",
    "\n",
    "sdata = rank\n",
    "rdata = comm.sendrecv(sdata, dest=to, source=fr)\n",
    "\n",
    "print(\"rank %d got data from %d\" %(rank, rdata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```\n",
    "rank 0 got data from 3\n",
    "rank 1 got data from 0\n",
    "rank 2 got data from 1\n",
    "rank 3 got data from 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Collective communication\n",
    "\n",
    "- All communication in MPI is within a group of processes\n",
    "     - Collective communication is over all of the processes in that group \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figures/collectives.png\" alt=\"Collective patterns\" width=\"400\"/>\n",
    "\n",
    "- Most algorithms are log(P)\n",
    "- They classify in 3 major communication patterns\n",
    "     - Scatter,\tGather,\tReduce\n",
    "     - Barrier,\tAllReduce,\tAllgather,\tAlltoall\n",
    "     - Scan,\tExscan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Collective communication\n",
    "\n",
    "- From the point of view of functionalities, there are three classes of operations\n",
    "    - **Synchronization**: Barrier\n",
    "    - **Data movement**: Broadcast, Gather, Scatter, Allgather, Alltoall\n",
    "    - **Collective computation**: Reduce, AllReduce, Scan, Exscan, Reduce_scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Syncronization\n",
    "\n",
    "`MPI_Barrier( comm )`\n",
    "\n",
    "- Blocks until all processes in the group of the communicator comm call it.\n",
    "- Programmers prefer not to use it in a parallel program\n",
    "    - Occasionally useful in measuring performance and load balancing\n",
    "    - It could increase performance by reducing network contention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "rank = MPI.COMM_WORLD.Get_rank()\n",
    "print(\"rank %d: before barrier\" %(rank))\n",
    "\n",
    "MPI.COMM_WORLD.barrier()\n",
    "\n",
    "print(\"rank %d: after barrier\" %(rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```\n",
    "rank 0: before barrier\n",
    "rank 1: before barrier\n",
    "rank 2: before barrier\n",
    "rank 3: before barrier\n",
    "rank 3: after barrier\n",
    "rank 1: after barrier\n",
    "rank 2: after barrier\n",
    "rank 0: after barrier\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Collective Data Movement\n",
    "\n",
    "\n",
    "- **One to all**\n",
    "    - Broadcast\n",
    "    - Scatter (personalized)\n",
    "- **All to one**\n",
    "    -  Gather\n",
    "\n",
    "\n",
    "- **All to all**\n",
    "    - Allgather\n",
    "    - Alltoall (personalized)\n",
    "\n",
    "\n",
    "<cite> All collective operations must be called by all processes in the communicator </cite>\n",
    "\n",
    "### Each process can get different data with the {function}v variant of each method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Collective communication semantics\n",
    "\n",
    "- Collective routines on the same communicator must be called in the same order on all participating processes\n",
    "\n",
    "- For multi-threaded processes (`MPI_THREAD_MULTIPLE`)\n",
    "    - it is the users responsibility to ensure order\n",
    "\n",
    "- Message tags are not used\n",
    "\n",
    "<div class=\"box\"> Use different communicators to separate collective operations on the same process </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Collective Data Movement \n",
    "\n",
    "![Collectives](./figures/move_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "MPI.COMM_WORLD.bcast(data, root=proc_id)\n",
    "MPI.COMM_WORLD.gather(data, root=proc_id)\n",
    "MPI.COMM_WORLD.scatter(data, root=proc_id)\n",
    "\n",
    "# for numpy arrays\n",
    "MPI.COMM_WORLD.Scatter(sendbuf, recvbuf, root=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Collective Data Movement \n",
    "\n",
    "![Collectives](./figures/move_data_all.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# sendobj is iterable\n",
    "MPI.COMM_WORLD.allgather(sendobj)\n",
    "MPI.COMM_WORLD.alltoall(sendobj)\n",
    "\n",
    "# for numpy arrays\n",
    "MPI.COMM_WORLD.Allgather([x,  MPI.DOUBLE], [xg, MPI.DOUBLE])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Collective Data Movement - Notes\n",
    "\n",
    "- `MPI_Allgather` is equivalent to\n",
    "    - `MPI_Gather` followed by `MPI_Bcast`\n",
    "    - Algorithms for `MPI_Allgather` are usually faster (try on ACCRE)\n",
    "\n",
    "- `MPI_Alltoall`\n",
    "    - Performs a “transpose” of the data\n",
    "    - Tricky to implement efficiently\n",
    "        - Implementation have a hard time scaling to the size of today's supercomputers\n",
    "        - For large messages point to point communication is preferable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Variants\n",
    "\n",
    "- The basic routines send the same amount of data from each process\n",
    "\n",
    "`MPI_Scatter(sbuf, 1, MPI_INT, rbuf, 100, MPI_INT, root, comm);`\n",
    "\n",
    "<div align=\"right\"><small>(*) sends one integer to each process</small></div>\n",
    "\n",
    "- Sending a different number of items to each process\n",
    "    - Example: `MPI_Scatterv`\n",
    "    - Routines with “v” (for vector) at the end \n",
    "        - allow to specify a different number of elements for each destination/source\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<div class=\"box\"> Efficient algorithms exist for these cases (not alltoall), not as fast as the simpler, basic routines </div>\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "**Variant alltoallw:** \n",
    "- Allows different datatypes, counts, and displacements for each partner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Collective Computation\n",
    "\n",
    "- Combines communication with computation\n",
    "     - Reduce\n",
    "         - All to one, with an operation to combine\n",
    "     - Scan, Exscan\n",
    "         - All prior ranks to all, with combination\n",
    "     - Reduce_scatter\n",
    "         - All to all, with combination\n",
    "\n",
    "\n",
    "### Combination operations \n",
    "- Can be either\n",
    "     - Predefined operations\n",
    "     - User defined operations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Reduction\n",
    "\n",
    "<img src=\"./figures/reduction.png\" alt=\"Reduce\" align=\"left\" width=\"477\"/>\n",
    "\n",
    "&nbsp;<br/>\n",
    "&nbsp;\n",
    "\n",
    "| MPI reduction operations include: | |\n",
    "--- | --- |\n",
    "| MPI.MAX | MPI.MIN |\n",
    "| MPI.SUM | |\n",
    "| MPI.PROD | |\n",
    "| MPI.LAND | MPI.RAND |\n",
    "| MPI.LOR | MPI.ROR |\n",
    "| MPI.MAXLOC | MPI.MINLOC |\n",
    "| MPI_BXOR | |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "MPI.COMM_WORLD.reduce(sendobj, op=MPI.SUM, root=0)\n",
    "MPI.COMM_WORLD.allreduce(sendobj, op=MPI.SUM)\n",
    "```\n",
    "\n",
    "- reduce is similar to gather but result is aggregated using different ops\n",
    "- allreduce is similar to allgather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Collective computation\n",
    "\n",
    "![Collectives](./figures/reduction_all.png)\n",
    "\n",
    "\n",
    "<div class=\"box\"> Allreduce, Exscan, Reduce, Reduce_scatter, and Scan take both built-in and user-defined combiner functions. </div>\n",
    "\n",
    "\n",
    "## All collectives\n",
    "- All versions deliver results to all participating processes\n",
    "- Most routines accept both intra- and intercommunicators\n",
    "   - Intercommunicator versions are collective between two groups of processes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Define your own collective routine\n",
    "\n",
    "\n",
    "```C++\n",
    "MPI_Op_create(user_fcn, commutes, &op);\n",
    "MPI_Op_free(&op);\n",
    "\n",
    "user_fcn(invec, inoutvec, len, datatype);\n",
    "```\n",
    "- Depending on the value of `commute`\n",
    "    - True: the operation should be both commutative and associative\n",
    "    - False: the order of operands is fixed \n",
    "        - defined to be in ascending, process rank order, beginning with process zero\n",
    "\n",
    "- The user function should perform:\n",
    "```C++\n",
    "for(i=0; i<len; i++)\n",
    "    inoutvec[i] = invec[i] op inoutvec[i];\n",
    "```\n",
    "\n",
    "*The operation op is always assumed to be associative.* \n",
    "*The user function can be non-commutative.* `Example?`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "```\n",
    "Matrix multiplication\n",
    "Substraction / Division\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Define your own collective example\n",
    "Product of complex number\n",
    "\n",
    "```C++\n",
    "user_fcn(invec, inoutvec, len, datatype);\n",
    "```\n",
    "python:\n",
    "```python\n",
    "user_fcn(inelem1, inelem2, outelem)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Complex import Complex\n",
    "# Complex class defined in a separate file\n",
    "\n",
    "def myprod(a, b, c):\n",
    "    c = Complex()\n",
    "    c.real = a.real * b.real - a.img * b.img\n",
    "    c.img = a.img * b.real + a.real * b.img\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Define your own collective example\n",
    "Product of complex number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm = size = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "a = Complex(rank + 1, rank)\n",
    "\n",
    "print(\"Rank %d: Data %s\" %(rank, a))\n",
    "\n",
    "myop = MPI.Op.Create(myprod, True) # commute is True\n",
    "b = comm.Reduce(a, op=myop, root=0)\n",
    "\n",
    "if rank==0:\n",
    "    print(\"Produc: %s\" %(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Rank 0: Data (1.0  0.0)\n",
    "Rank 1: Data (2.0  1.0)\n",
    "Rank 3: Data (4.0  3.0)\n",
    "Rank 2: Data (3.0  2.0)\n",
    "Product: (-5.0 40.0)\n",
    "```\n",
    "<cite> For C version https://www.mpi-forum.org/docs/mpi-1.1/mpi-11-html/node80.html </cite>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Define your own collective example\n",
    "\n",
    "- Numpy arrays are trickier \n",
    "    - Programmer needs to manually pack/unpack data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def unpack_array(array_mem, dt):\n",
    "    a = array_mem.tobytes()\n",
    "    itemsize = dt.Get_size()\n",
    "    array_len = int(array_mem.shape[0])\n",
    "    unpack_array = []\n",
    "    for i in range(int(array_len/itemsize)):\n",
    "        unpack_array.append(int(np.frombuffer(a[itemsize*i:itemsize*(i+1)],\n",
    "                            dtype=np.int64)))\n",
    "    return np.array(unpack_array)\n",
    "\n",
    "def myprod(xmem, ymem, dt):\n",
    "    a = unpack_array(xmem, dt)\n",
    "    b = unpack_array(ymem, dt)\n",
    "\n",
    "    c = np.array([0] * len(a))\n",
    "    for i in range(len(a)):\n",
    "        c[i] = a[i] % 2 | b[i] % 2\n",
    "\n",
    "    ymem[:] = memoryview(bytearray(c))[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Define your own collective example\n",
    "\n",
    "- Numpy arrays are trickier \n",
    "    - Programmer needs to manually pack/unpack data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([rank * (i + 1) for i in range(3)])\n",
    "b = np.array([0] * 3)\n",
    "print(\"Rank %d: Data %s\" %(rank, a))\n",
    "\n",
    "myop = MPI.Op.Create(myprod, True) # commute is True\n",
    "comm.Reduce([a, MPI.DOUBLE], [b, MPI.DOUBLE], op=myop, root=0)\n",
    "\n",
    "if rank==0:\n",
    "    print(\"Contains odd numbers: %s\" %(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Rank 0: Data [0 0 0]\n",
    "Rank 2: Data [2 4 6]\n",
    "Rank 1: Data [1 2 3]\n",
    "Rank 3: Data [3 6 9]\n",
    "Contains odd numbers: [1 0 1]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"box\"> Another example in the unit test code for mpi4py: https://github.com/mpi4py/mpi4py/blob/master/test/test_op.py</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Non-Blocking Collective Operations\n",
    "\n",
    "- MPI-3 introduced nonblocking versions of collective operations\n",
    "     - All return an `MPI_Request`, use the usual `MPI_Wait`, `MPI_Test`, etc. to complete.\n",
    "     - May be mixed with point-to-point and other MPI_Requests\n",
    "     - Not necessary faster\n",
    "    - Follow same ordering rules as blocking operations\n",
    "\n",
    "- `MPI_Ibarrier`\n",
    "     - Useful for distributed termination detection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Topologies and Neighborhood\n",
    "\n",
    "<img src=\"./figures/topologies.png\" alt=\"Topology mapping\" width=\"500\"/>\n",
    "\n",
    "<div align=\"right\"> <small> (*) Image from: Advanced MPI 2.2 and 3.0 Tutorial by Torsten Hoefler</small> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Topologies\n",
    "\n",
    "-  A **virtual topology** represents the way that MPI processes communicate\n",
    "      - Nearest neighbor exchange in a mesh\n",
    "      - Recursive doubling in an all-to-all exchange\n",
    "\n",
    "-  A **physical topology** represents that connections between the cores, chips, and nodes in the hardware\n",
    "\n",
    "<div class=\"box\"> Mapping of the virtual topology onto the physical topology. <br/> Think of nodes of chips of cores - not trivial </div>\n",
    "\n",
    "\n",
    "### Topology mapping basics\n",
    "- Allocation mapping \n",
    "- Rank reordering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Topology Mapping Basics\n",
    "\n",
    "### Allocation mapping\n",
    "- Up-front specification of communication pattern\n",
    "- Batch system picks good set of nodes for given topology\n",
    "\n",
    "\n",
    "- Properties:\n",
    "     - Not supported by current batch systems\n",
    "     - Either predefined allocation, random allocation, or “global bandwidth maximation”\n",
    "     - Not always possible to specify communication pattern upfront\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Topology Mapping Basics\n",
    "\n",
    "### Rank reordering\n",
    "- Change numbering in a given allocation to reduce congestion\n",
    "- Sometimes automatic\n",
    "\n",
    "\n",
    "- Properties:\n",
    "    - Always possible, but effect may be limited (e.g., in a bad allocation)\n",
    "    - Allows manual shuffling through MPI process topologies\n",
    "         - Network topology is not exposed\n",
    "    - Data has to be manual shuffled after remapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# MPI’s Topology Routines\n",
    "- MPI provides routines to create new communicators that order the process ranks\n",
    "\n",
    "-  Two types of virtual topology supported:\n",
    "      - **Cartesian (regular mesh)**\n",
    "      - Graph (several ways to define in MPI)\n",
    "          - Routine evolved in each version of MPI\n",
    "\n",
    "-  Additional routines provide access to the defined virtual topology\n",
    "-  (Virtual) topologies are properties of a communicator\n",
    "      - Topology routines all create a new communicator with properties of the specified virtual topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# MPI_Cart_create\n",
    "\n",
    "- Creates a new communicator newcomm from oldcomm\n",
    "    - representing an ndim dimensional mesh with sizes dims\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "```C++\n",
    "MPI_Cart_create(MPI_Comm oldcomm, int ndim, int dims[],\n",
    "                int qperiodic[], int qreorder, MPI_Comm *newcomm)\n",
    "```\n",
    "    \n",
    "- The mesh is periodic in coordinate direction i if `qperiodic[i]` is true (torus). \n",
    "\n",
    "- The ranks in the new communicator are reordered \n",
    "    - to better match the physical topology\n",
    "    - if qreorder is true\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<div class=\"box\">  \n",
    "Some processes may return MPI_COMM_NULL. <br/> \n",
    "Product sum of dims must be <= P \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# MPI_Dims_create\n",
    "\n",
    "- Fill in the dims array such that the product of `dims[i] for i=0 to ndim-1` equals nnodes.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "```C++\n",
    "MPI_Dims_create(int nnodes, int ndim, int dims[])\n",
    "```\n",
    "\n",
    "- Any value of `dims[i]` that is 0 on input will be replaced\n",
    "    - values that are > 0 will not be changed\n",
    "\n",
    "- Makes life easier\n",
    "    - Some problems might work better with non-square layouts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Example\n",
    "\n",
    "**3D torus**\n",
    "\n",
    "```C++\n",
    "int p;\n",
    "\n",
    "MPI_Comm_size(MPI_COMM_WORLD, &p);\n",
    "MPI_Dims_create(p, 3, dims);\n",
    "\n",
    "int periods[3] = {1,1,1};\n",
    "\n",
    "MPI_Comm cart_comm;\n",
    "MPI_Cart_create(comm, 3, dims, periods, 0, &cart_comm);\n",
    "```\n",
    "- Reorder argument allows for topology mapping\n",
    "     - Each calling process may have a new rank in the created communicator\n",
    "     - Data has to be remapped manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Example python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "world_rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "dims = MPI.Compute_dims(size, [0]*2)\n",
    "cart_comm = comm.Create_cart(\n",
    "        dims, periods=[True,True], reorder=True)\n",
    "\n",
    "new_rank = cart_comm.Get_rank()\n",
    "\n",
    "print(\"World rank: %d -- Cart rank: %d\" %(\n",
    "    world_rank, new_rank));\n",
    "\n",
    "cart_comm.Free()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "World rank: 2 -- Cart rank: 2\n",
    "World rank: 1 -- Cart rank: 1\n",
    "World rank: 3 -- Cart rank: 3\n",
    "World rank: 0 -- Cart rank: 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Cartesian Query Functions\n",
    "\n",
    "- Determine neighbor ranks\n",
    "    - Can be computed from rank (in the cart_comm), dims, and periods\n",
    "        - Ordering defined in MPI\n",
    "        - See Section 7.5 in MPI-3 Standard\n",
    "        \n",
    "        \n",
    "- `MPI_Cartdim_get()`\n",
    "     - Gets dimensions of a Cartesian communicator\n",
    "- `MPI_Cart_get()`\n",
    "     - Gets size of dimensions\n",
    "- `MPI_Cart_rank()`\n",
    "     - Translate coordinates to rank\n",
    "- `MPI_Cart_coords()`\n",
    "     - Translate rank to coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# MPI_Cart_shift\n",
    "\n",
    "- Returns the ranks of the processes that are a shifted by **disp** steps in coordinate **direction**\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "```C++\n",
    "MPI_Cart_shift(MPI_Comm comm, int direction, int disp,\n",
    "               int *rank_source, int *rank_dest)\n",
    "```\n",
    "\n",
    "- Useful for nearest neighbor communication in the coordinate directions\n",
    "     - Dimensions are numbered from 0 to ndims-1\n",
    "     - Displacement indicates neighbor distance (-1, 1, 2)\n",
    "     - May return MPI_PROC_NULL\n",
    "         - The source or destination for the shift is out of range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Example (8 processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim = 2\n",
    "\n",
    "dims = MPI.Compute_dims(size, [0]*ndim)\n",
    "cart_comm = comm.Create_cart(dims, periods=[True,True], reorder=True)\n",
    "\n",
    "new_rank = cart_comm.Get_rank()\n",
    "if new_rank==0:\n",
    "    print(\"Cartesian dim: %s\" %(dims))\n",
    "\n",
    "for i in range(ndim):\n",
    "    for d in (-1, +1):\n",
    "        source, dest = cart_comm.Shift(i, d)\n",
    "        if new_rank == 0:\n",
    "            print(\"Dir %d, disp %d - Src %d - Dest %d\" %(i, d, source, dest));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"./figures/shift.png\" alt=\"MPI_shift\" align=\"right\" width=\"300\"/>\n",
    "\n",
    "```\n",
    "Cartesian dim: [4, 2]\n",
    "Dir 0, disp -1 - Src 2 - Dest 6\n",
    "Dir 0, disp 1 - Src 6 - Dest 2\n",
    "Dir 1, disp -1 - Src 1 - Dest 1\n",
    "Dir 1, disp 1 - Src 1 - Dest 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Advanced topology concepts\n",
    "\n",
    "### Graph Topology\n",
    "\n",
    "- MPI provides routines to specify a general graph virtual topology\n",
    "    - Graph vertices represent MPI processes (usually one per process)\n",
    "    - Graph edges indicate important connections\n",
    "\n",
    "### Collectives on topologies\n",
    "- Since MPI-3\n",
    "     - Collective communications only cover some patterns\n",
    "         - E.g., no stencil pattern\n",
    "     - Example: `MPI_Neighbor_allgather`\n",
    "\n",
    "### Reading\n",
    "\n",
    "\n",
    "<div>\n",
    "    <em>Generic Topology Mapping Strategies for Large-scale Parallel Architectures</em><br/>\n",
    "Hoefler and Snir<br/>\n",
    "   <a href=\"http://dx.doi.org/10.1145/1995896.1995909\"> http://dx.doi.org/10.1145/1995896.1995909</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Profiling\n",
    "\n",
    "Profiling interface: PMPI routines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Determinism in MPI\n",
    "\n",
    "- In exact arithmetic, you always get the same results\n",
    "     - but roundoff error, truncation can happen\n",
    "\n",
    "- Message-passing programming models are by default nondeterministic\n",
    "    - The arrival order of messages sent from two processes, A and B, to a third process, C, is not defined.\n",
    "    - MPI does guarantee that two messages sent from one process, A, to another process, B, will arrive in the order sent.\n",
    "    - It is the programmer's responsibility to ensure that a computation is deterministic when this is required.\n",
    "    \n",
    "- **How can we \"ensure\" determinism?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Use source and tag (not `MPI_ANY_SOURCE` or `MPI_ANY_TAG`)\n",
    "2. Use synchronization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# How Deterministic are Collective Computations? \n",
    "\n",
    "- Depending on the process to hardware mapping \n",
    "    - Messages can arrive in different order to processes\n",
    "    - Round-off error may cause slight differences\n",
    "\n",
    "- Reduction results might be different for non-associative operations\n",
    "    - Even if they are commutative\n",
    "\n",
    "- Allreduce **does** guarantee that the same value is received by all processes for each call\n",
    "\n",
    "- Why didn’t MPI mandate determinism?\n",
    "     - Not all applications need it\n",
    "     - Implementations of collective algorithms can use “deferred synchronization” ideas to provide better performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Timing MPI Programs\n",
    "\n",
    "- The elapsed (wall-clock) time between two points in an MPI program can be computed using `MPI_Wtime`:\n",
    "\n",
    "```C++\n",
    " double t1, t2;\n",
    " t1 = MPI_Wtime();\n",
    " ...\n",
    " t2 = MPI_Wtime();\n",
    " printf( \"time is %d\\n\", t2 - t1 );\n",
    "```\n",
    "\n",
    "-  The value returned by a single call to MPI_Wtime has little value.\n",
    "-  The resolution of the timer is returned by `MPI_Wtick`\n",
    "-  Times in general are local, but an implementation might offer synchronized times.\n",
    "     - For advanced users: see the MPI attribute `MPI_WTIME_IS_GLOBAL`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Example Bcast time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "comm.barrier();\n",
    "local_wt = MPI.Wtime();\n",
    "\n",
    "data = np.array([rank * i for i in range(10)])\n",
    "comm.Bcast(data, root=0);\n",
    "local_wt = MPI.Wtime() - local_wt;\n",
    "\n",
    "wt = comm.reduce(local_wt, op=MPI.MAX, root=0);\n",
    "\n",
    "if rank == 0:\n",
    "    print(\"Bcast time %f\" %(wt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Bcast time 0.004041\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**How accurate is this measurement?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# PMPI routines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PMPI allows selective interception of MPI routines at link time \n",
    "    - No need to recompile (for C and Fortran)\n",
    "    - Interposition library contains wrapper functions\n",
    "    \n",
    "<img src=\"./figures/pmpi.png\" alt=\"PMPI\" width=\"600\"/>\n",
    "\n",
    "- Program is linked to interposition library\n",
    "    - All functions are available under two names: MPI_xxx and PMPI_xxx\n",
    "        - MPI_xxx symbols are weak, can be over-written\n",
    "    - Measurement code in the interposition library measures \n",
    "\n",
    "<cite> Not all MPI functions need to be instrumented </cite>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# PMPI example (C/C++)\n",
    "\n",
    "- Count number of calls to the `Send` routine for each rank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include \"mpi.h\"\n",
    "\n",
    "static int numsend = 0;\n",
    "\n",
    "int MPI_Send(void *buf, int count, MPI_Datatype type,\n",
    "             int dest, int tag, MPI_Comm comm) {\n",
    "    numsend++;\n",
    "    return PMPI_Send(buf, count, type, dest, tag, comm);\n",
    "}\n",
    "\n",
    "int MPI_Finalize() {\n",
    "    int me;\n",
    "    PMPI_Comm_rank(MPI_COMM_WORLD, &me);\n",
    "    printf(\"%d sent %d messages.\\n\", me, numsend);\n",
    "    return PMPI_Finalize();\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Writing PMPI wrappers\n",
    "\n",
    "- Use rank in `MPI_COMM_WORLD` as process identifier\n",
    "    - Data volume: `#elements * PMPI_Type_size(type)`\n",
    "- MPI does not provide a message ID\n",
    "     - Custom functions to record complete traffic \n",
    "         - if you need to match send and recv events\n",
    "- Wildcard message source and tag\n",
    "     - You can record real values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Profiling tools\n",
    "\n",
    "### Tracing\n",
    "\n",
    "- Recoding of individual time-stamped program events as opposed to aggregated information\n",
    "     - Entering and leaving a function\n",
    "     - Sending and receiving a message\n",
    "\n",
    "\n",
    "<img src=\"./figures/vampir.png\" alt=\"Vampir\" align=\"right\" width=\"200\"/>\n",
    "\n",
    "Intel Trace Analyzer: https://researchcomputing.princeton.edu/faq/using-intel-trace-analyze \n",
    "\n",
    "VAMPIR: https://vampir.eu/ \n",
    "\n",
    "### Profiling\n",
    "\n",
    " ParaProf: http://www.cs.uoregon.edu/research/tau/vihps14/ParaProf.pdf \n",
    "\n",
    "cprofile module in python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Code\n",
    "\n",
    "### All the code from this slides can be downloaded from https://github.com/anagainaru/MPI_Lectures\n",
    "\n",
    "- Scalability example: vector matrix multiplication\n",
    "    - You are encouraged to run the examples on ACCRE\n",
    "\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<div class=\"box\"> For questions: ana.gainaru@vanderbilt.edu </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Useful links\n",
    "\n",
    "### mpi4py \n",
    "\n",
    "- github: https://github.com/mpi4py/mpi4py\n",
    "- download and brief tutorial: www.mpi4py.com\n",
    "- complete tutorial: https://www.bu.edu/pasi/files/2011/01/Lisandro-Dalcin-mpi4py.pdf\n",
    "https://buildmedia.readthedocs.org/media/pdf/mpi4py/3.0.0/mpi4py.pdf\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "### MPI \n",
    "\n",
    "- Standard (current 4.0): https://www.mpi-forum.org/\n",
    "- Tutorial: https://mpitutorial.com/tutorials\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<div class=\"box\"> For questions: ana.gainaru@vanderbilt.edu </div> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
